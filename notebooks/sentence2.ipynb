{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from elastic import elastic_session, ScrollingCorpus, ElasticDocument\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence import doc_to_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = elastic_session(\"arxiv-index\", \"../credentials.json\", \"../http_ca.crt\")\n",
    "doc = ElasticDocument(session, 0, text_path=\"article\")\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "sentences = doc_to_sentences(doc, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import starmap, pairwise\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "def print_pairs(sentences):\n",
    "    console = Console()\n",
    "    console.clear()\n",
    "\n",
    "    table = Table()\n",
    "    table.add_column(\"Sentence Pair\")\n",
    "    table.add_column(\"Similarity\", vertical=\"top\")\n",
    "\n",
    "    for thing in starmap(lambda x, y: (x,y,x.sim(y)), pairwise(sentences)):\n",
    "        mytext = f'''\n",
    "- {thing[0].text.strip()}\n",
    "\n",
    "\n",
    "- {thing[1].text.strip()}\n",
    "\n",
    "---\n",
    "        '''\n",
    "        table.add_row(Markdown(mytext), \"\\n\\n\"+str(thing[2]))\n",
    "\n",
    "    console.print(table)\n",
    "\n",
    "sentences = sentences[:20]\n",
    "print_pairs(sentences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence import SimilarityPair, SentenceChain, Sentence, SentenceLike\n",
    "from itertools import chain\n",
    "\n",
    "def iterative_merge(sentences: list[SentenceLike],*, threshold: float, round_limit: int | None = 1, pooling_method=\"average\"):\n",
    "    pairs = [SimilarityPair.from_sentences(s1, s2) for s1, s2 in pairwise(sentences)]\n",
    "\n",
    "    #No more merging can happen\n",
    "    if not any(filter(lambda x: x.sim > threshold, pairs)):\n",
    "        return sentences\n",
    "\n",
    "    chains = []\n",
    "\n",
    "    for i, pair in enumerate(pairs):\n",
    "        if pair.sim >= threshold: #Add to the chain\n",
    "            if i == 0:\n",
    "                chains.append([pair.s1, pair.s2])\n",
    "            else:\n",
    "                #We have already examined s1\n",
    "                chains[-1] += [pair.s2]\n",
    "\n",
    "        else: #Create new chain for this sentence\n",
    "            if i == 0:\n",
    "                chains.append([pair.s1, pair.s2])\n",
    "            else:\n",
    "                #We have already examined s1\n",
    "                chains.append([pair.s2])\n",
    "\n",
    "    result = [SentenceChain(c, pooling_method) for c in chains]\n",
    "    \n",
    "    if round_limit is None:\n",
    "        return iterative_merge(result, threshold, None)\n",
    "    elif round_limit > 1:\n",
    "        return iterative_merge(result, threshold, round_limit-1)\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pairs(merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
